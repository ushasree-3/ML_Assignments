In this question you will implement and compare the following different KNN variants (we will discuss the a) and b) part of this in the upcoming tutorial)

   - LSH (1.5 marks)
   - KD-tree (1.5 marks)
   - Naive version of KNN (0.5 marks)

Vary dataset size $N$, number of dimensions $D$ to do training and testing time and memory comparison for finding $K$ nearest neighbours. (1 mark)
Now, in a 2d randomly generated dataset visually show how many of the $K$ closest neighbours appx. $K$ NN methods miss out due to their approximate nature. 

Also show the partitions in the 2d space. (0.5 marks)
