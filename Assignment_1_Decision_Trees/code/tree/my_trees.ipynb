{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b099747-e422-48c6-a795-0095079ecd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# The current code given is for the Assignment 1.\n",
    "# You will be expected to use this to make trees for:\n",
    "# > discrete input, discrete output\n",
    "# > real input, real output\n",
    "# > real input, discrete output\n",
    "# > discrete input, real output\n",
    "# \"\"\"\n",
    "# from dataclasses import dataclass\n",
    "# from typing import Literal\n",
    "# import sys\n",
    "# sys.path.append(\"..\")\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tree.utils import *\n",
    "\n",
    "# N = 30 # no: of samples\n",
    "# P = 5 # no : of features\n",
    "# X = pd.DataFrame({i: pd.Series(np.random.randint(P, size=N), dtype=\"category\") for i in range(5)})\n",
    "# y = pd.Series(np.random.randn(N))\n",
    "\n",
    "# np.random.seed(42)\n",
    "\n",
    "# class Node:\n",
    "#     def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "#         self.feature = feature\n",
    "#         self.threshold = threshold\n",
    "#         self.left = left\n",
    "#         self.right = right\n",
    "#         self.value = value\n",
    "\n",
    "# @dataclass\n",
    "# class DecisionTree:\n",
    "#     criterion: Literal[\"information_gain\", \"gini_index\"]  # criterion won't be used for regression\n",
    "#     max_depth: int  # The maximum depth the tree can grow to\n",
    "\n",
    "#     def __init__(self, criterion, max_depth=5):\n",
    "#         self.criterion = criterion\n",
    "#         self.max_depth = max_depth\n",
    "        \n",
    "#     def fit(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "#         \"\"\"\n",
    "#         Function to train and construct the decision tree\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # If you wish your code can have cases for different types of input and output data (discrete, real)\n",
    "#         # Use the functions from utils.py to find the optimal attribute to split upon and then construct the tree accordingly.\n",
    "#         # You may(according to your implemetation) need to call functions recursively to construct the tree. \n",
    "\n",
    "#         pass\n",
    "\n",
    "#     def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "#         \"\"\"\n",
    "#         Funtion to run the decision tree on test inputs\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Traverse the tree you constructed to return the predicted values for the given test inputs.\n",
    "\n",
    "#         pass\n",
    "\n",
    "#     def plot(self) -> None:\n",
    "#         \"\"\"\n",
    "#         Function to plot the tree\n",
    "\n",
    "#         Output Example:\n",
    "#         ?(X1 > 4)\n",
    "#             Y: ?(X2 > 7)\n",
    "#                 Y: Class A\n",
    "#                 N: Class B\n",
    "#             N: Class C\n",
    "#         Where Y => Yes and N => No\n",
    "#         \"\"\"\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d0ffd24-338f-445e-8ae2-00e5c1ba866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Literal\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tree.utils import *\n",
    "\n",
    "def MSE(series):\n",
    "    series_MSE = 0\n",
    "    mean = np.mean(series)\n",
    "    for i in series:\n",
    "        series_MSE += (mean - i)**2\n",
    "    return series_MSE\n",
    "    \n",
    "def information_gain(Y: pd.Series, attr: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Function to calculate the information gain\n",
    "    \"\"\"\n",
    "    # if check_ifreal(Y) and not check_ifreal(attr):\n",
    "    dist_target = attr.value_counts(normalize=True)\n",
    "    normalized_target = dist_target/dist_target.sum()\n",
    "    IG = MSE(Y)\n",
    "    for value, p in normalized_target.items():\n",
    "        series = Y[attr == value]\n",
    "        IG = IG - p * MSE(series) # 1e-6 is added to avoid log(0)\n",
    "    return IG\n",
    "    \n",
    "def opt_split_attribute(X: pd.DataFrame, y: pd.Series):\n",
    "    IG_list = {}\n",
    "    for i in X:\n",
    "        IG_list[i] = information_gain(y, X[i])\n",
    "    IGvalues = list(IG_list.values())\n",
    "    IGkeys = list(IG_list.keys())\n",
    "    return IGkeys[IGvalues.index(max(IGvalues))]\n",
    "    \n",
    "N = 30 # no: of samples\n",
    "P = 5 # no : of features\n",
    "X = pd.DataFrame({i: pd.Series(np.random.randint(P, size=N), dtype=\"category\") for i in range(5)})\n",
    "y = pd.Series(np.random.randn(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d8f103dd-e83f-404f-83b8-6006798e0cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(opt_split_attribute(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "259f8760-e7b5-4eaa-af34-a7aa84f0faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_elements_equal(series):\n",
    "    return series.nunique() == 1\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.Series, max_depth = 5, name=None):\n",
    "        self.name = name\n",
    "        feature = opt_split_attribute(X,y)\n",
    "        self.feature = feature\n",
    "        self.value = None\n",
    "        self.child = []\n",
    "        if max_depth == 1 or all_elements_equal(y):\n",
    "            avg = 0\n",
    "            for i in y:\n",
    "                avg += i\n",
    "            avg = avg/len(y)\n",
    "            self.value = avg\n",
    "            return None\n",
    "        for each in X[feature].unique():\n",
    "            X_new = X[X[feature] == each]\n",
    "            y_new = y[X[feature] == each]\n",
    "            X_new = X_new.drop(feature, axis=1)\n",
    "            self.child.append(Node(X_new,y_new,max_depth-1,each))\n",
    "\n",
    "@dataclass\n",
    "class DecisionTree:\n",
    "    criterion: Literal[\"information_gain\", \"gini_index\"]  # criterion won't be used for regression\n",
    "    max_depth: int  # The maximum depth the tree can grow to\n",
    "\n",
    "    def __init__(self, criterion, max_depth=5):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        \"\"\"\n",
    "        Function to train and construct the decision tree\n",
    "        \"\"\"\n",
    "        self.tree = Node(X,y,self.max_depth,\"root\")\n",
    "        # If you wish your code can have cases for different types of input and output data (discrete, real)\n",
    "        # Use the functions from utils.py to find the optimal attribute to split upon and then construct the tree accordingly.\n",
    "        # You may(according to your implemetation) need to call functions recursively to construct the tree. \n",
    "        pass\n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Function to run the decision tree on test inputs\n",
    "        \"\"\"\n",
    "        y_hat = []\n",
    "        for _, row in X.iterrows():\n",
    "            node = self.tree\n",
    "            while node.value is None:\n",
    "                feature_value = row[node.feature]\n",
    "                for child in node.child:\n",
    "                    if child.name == feature_value:\n",
    "                        node = child\n",
    "                        break\n",
    "            y_hat.append(node.value)\n",
    "        return pd.Series(y_hat)\n",
    "        \n",
    "    def plot(self) -> None:\n",
    "        \"\"\"\n",
    "        Function to plot the tree\n",
    "\n",
    "        Output Example:\n",
    "        ?(X1 > 4)\n",
    "            Y: ?(X2 > 7)\n",
    "                Y: Class A\n",
    "                N: Class B\n",
    "            N: Class C\n",
    "        Where Y => Yes and N => No\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65517005-c976-4097-a119-0d48e180180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criteria : information_gain\n"
     ]
    }
   ],
   "source": [
    "for criteria in [\"information_gain\"]:\n",
    "    tree = DecisionTree(criterion=criteria)  # Split based on Inf. Gain\n",
    "    tree.fit(X, y)\n",
    "    y_hat = tree.predict(X)\n",
    "    tree.plot()\n",
    "    print(\"Criteria :\", criteria)\n",
    "    # print(\"RMSE: \", rmse(y_hat, y))\n",
    "    # print(\"MAE: \", mae(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1985a6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
